## Explicación del flujo de `script3.ipynb` (V1)

Este notebook implementa un flujo completo de clasificación para detección de phishing usando `GaussianNB` con selección de características por Información Mutua y optimización de hiperparámetros vía `GridSearchCV`. El dataset `Training Dataset.arff` contiene 30 variables predictoras y la variable objetivo `Result` con etiquetas {-1: phishing, 1: legítimo}. La idea central es construir primero una línea base, luego optimizar el modelo y, finalmente, ajustar el umbral de decisión para balancear precisión y recall en la clase de interés (phishing = -1).

El proceso comienza con la configuración de librerías, la fijación de la semilla y la carga del dataset `.arff`. Tras convertir tipos y asegurar que todas las columnas sean numéricas, se valida que no existan valores faltantes y se confirma que la variable objetivo `Result` es entera con valores -1 y 1. Se analiza la distribución de clases, que resulta razonablemente balanceada (ratio ≈ 0.80), por lo que no se aplican técnicas de rebalanceo como SMOTE. También se muestran gráficos de barras y torta para consolidar este diagnóstico, estableciendo que una división estratificada será suficiente para mantener las proporciones.

Luego se separan las variables predictoras (`X`) de la variable objetivo (`y`) y se realiza una división estratificada 70/15/15 en conjuntos de entrenamiento, validación y prueba. Esta estrategia permite entrenar y seleccionar modelos con `train`, buscar hiperparámetros y umbrales con `val`, y reservar `test` estrictamente para la evaluación final. Se verifica explícitamente que las proporciones de clase se preservan en los tres conjuntos.

Antes de entrenar modelos, se calcula la Información Mutua (MI) entre cada feature y la clase usando exclusivamente el conjunto de entrenamiento, evitando fugas de información. Con esto se obtiene un ranking de las variables más informativas para la clase -1, que luego se utiliza en un esquema de selección de características dentro de un `Pipeline`. El pipeline integra `SelectKBest(score_func=mutual_info_classif)` y `GaussianNB`, de manera que la selección de features se haga en cada fold de validación cruzada y forme parte del proceso de optimización.

La optimización de hiperparámetros se realiza con `GridSearchCV` empleando validación cruzada estratificada de 5 pliegues y la métrica de `f1_score` configurada con `pos_label=-1` para priorizar el desempeño sobre la clase phishing. Se exploran dos dimensiones: la cantidad de features `selector__k` (p.ej., 10, 15, 20, 25, 30) y el suavizado `clf__var_smoothing` de `GaussianNB` (una grilla logarítmica). `GridSearchCV` se ejecuta en paralelo (`n_jobs=-1`), ajusta automáticamente el mejor modelo (`refit=True`) y deja disponible `best_estimator_`, `best_params_` y `best_score_`. Tras la búsqueda, se listan los resultados y se evalúa el mejor pipeline sobre validación y prueba con el umbral estándar de 0.5 para contar con una primera línea de comparación.

En paralelo a ese pipeline optimizado, se entrena también un modelo base de `GaussianNB` sin cambios de hiperparámetros para establecer un baseline claro. Este modelo se evalúa en validación y prueba, generando métricas y matrices de confusión. La comparación inicial suele mostrar que el pipeline con selección de features y ajuste de `var_smoothing` tiende a mejorar la F1 respecto del baseline, aunque con el umbral 0.5 puede haber trade-offs marcados entre precisión y recall.

La etapa final del flujo se centra en el ajuste de umbral del pipeline optimizado. A partir de las probabilidades de la clase phishing (salida de `predict_proba`), se calcula la curva Precision–Recall en el conjunto de validación y se prueba una rejilla de umbrales entre 0.05 y 0.95. Se elige el umbral que maximiza el F1 de la clase -1 y, con ese valor, se recalculan métricas y la matriz de confusión tanto en validación como en prueba. Este paso es clave porque, al mover el umbral por encima de 0.5, suele aumentar notablemente la precisión (menos falsas alarmas) a costa de una reducción del recall; el notebook reporta explícitamente ese balance y muestra que el F1 global mejora con el umbral óptimo. Finalmente, se presentan tablas y gráficos comparando el desempeño del modelo base (umbral 0.5) frente al pipeline optimizado con el umbral afinado.

En síntesis, el flujo queda así: se cargan y validan los datos, se realiza el split 70/15/15 estratificado, se calcula el ranking de features por Información Mutua en entrenamiento, se entrena un pipeline `SelectKBest + GaussianNB` optimizado con `GridSearchCV` priorizando F1 de la clase phishing, se obtiene el mejor modelo y se evalúa con umbral 0.5, se entrena un baseline para referencia y, por último, se ajusta el umbral del pipeline para maximizar F1 en validación y se reporta el impacto final en prueba. No falta la optimización de hiperparámetros; está implementada y, además, complementada por un ajuste explícito de umbral que mejora el F1 en la clase relevante. Como nota operativa, el notebook contiene dos bloques que ejecutan `GridSearchCV`: el primero integra selección de features y cálculo de métricas completas; el segundo vuelve a ejecutar la búsqueda y presenta un resumen y una visualización centrada en recall. Podrías dejar solo uno para simplificar, pero funcionalmente ambos confirman la misma idea: el modelo se optimiza con CV y la métrica objetivo es F1 sobre la clase -1.