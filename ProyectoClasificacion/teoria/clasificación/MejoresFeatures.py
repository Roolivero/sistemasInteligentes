# ============================================
# ClasificaciÃ³n de sitios phishing con GaussianNB
# Esta tÃ©cnica se asocia a las metaheurÃ­sticas de bÃºsqueda global basadas en
# Monte Carlo, ya que utiliza muestreo aleatorio repetido para explorar
# subsets de variables en un espacio combinatorial muy grande.
# De este modo, aproxima una soluciÃ³n de alta calidad sin
# necesidad de evaluar todas las combinaciones posibles.
# ============================================

import pandas as pd
import numpy as np
import os
import joblib
from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score,
    f1_score, confusion_matrix, classification_report
)
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.io import arff
import random
from collections import Counter

RANDOM_STATE = 42

# Crear carpeta de salida si no existe
output_dir = "resultados_phishing"
os.makedirs(output_dir, exist_ok=True)

# =========================
# 1. Cargar dataset ARFF
# =========================
data, meta = arff.loadarff("/Users/lucila/PycharmProjects/SistemasInteligentes/clasificaciÃ³n/phishing+websites/Training Dataset.arff")
df = pd.DataFrame(data)

# ConversiÃ³n de atributos categÃ³ricos leÃ­dos como bytes
df = df.apply(lambda col: col.str.decode('utf-8') if col.dtype == 'object' else col)
df["Result"] = df["Result"].astype(int)

print("Shape:", df.shape)
print(df['Result'].value_counts())

df.to_csv(os.path.join(output_dir, "dataset_preprocesado.csv"), index=False)

# =========================
# 2. DistribuciÃ³n de clases
# =========================
plt.figure()
df['Result'].value_counts().plot(kind="bar", title="DistribuciÃ³n de clases")
plt.savefig(os.path.join(output_dir, "distribucion_clases.png"))
plt.close()

# =========================
# 3. Separar datos
# =========================
X = df.drop("Result", axis=1)
y = df["Result"]

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=RANDOM_STATE,
    stratify=y
)

# =========================
# Random Search de subsets + Log en disco
# =========================
random.seed(RANDOM_STATE)

N_ITER = 500  # ajustar segÃºn tiempo disponible
K = 5  # tamaÃ±o del subset seleccionado

features = X_train.columns.tolist()
mejor_f1 = 0
mejor_subset = None

resultados = []
freq_optimos = Counter()  # contador de features mÃ¡s frecuentes en Ã³ptimos locales

log_path = os.path.join(output_dir, "log_random_search_subsets.csv")
freq_path = os.path.join(output_dir, "frecuencias_optimos.csv")

print("\nğŸ” Iniciando Random Search de subsets...\n")

for i in range(N_ITER):
    subset = random.sample(features, K)

    model = GaussianNB()
    model.fit(X_train[subset], y_train)
    y_pred = model.predict(X_test[subset])
    f1 = f1_score(y_test, y_pred)

    resultados.append({
        "iteracion": i + 1,
        "subset": subset,
        "f1_score": f1
    })

    if f1 > mejor_f1:
        mejor_f1 = f1
        mejor_subset = subset

        # actualizar el contador de features que aparecen en Ã³ptimos locales
        freq_optimos.update(subset)

        print(f"â­ Ã“ptimo local en iteraciÃ³n {i + 1}/{N_ITER}")
        print(f"   F1-score: {f1:.4f}")
        print(f"   Variables: {subset}\n")
        print("ğŸ“ˆ Frecuencias actuales de features mÃ¡s frecuentes:")
        print(freq_optimos.most_common(10))
        print("\n")

        # Guardado incremental del log
        pd.DataFrame(resultados).sort_values(
            by="f1_score", ascending=False
        ).to_csv(log_path, index=False)

        # Guardado incremental del ranking de features
        pd.DataFrame(freq_optimos.most_common()).to_csv(freq_path, index=False,
                                                        header=["feature", "frecuencia"])

print("\nâœ… BÃºsqueda finalizada")
print(f"ğŸ† Mejor F1-score global: {mejor_f1:.4f}")
print(f"ğŸ† Mejor subset encontrado:")
print(mejor_subset)

# Guardado final consolidado
df_resultados = pd.DataFrame(resultados).sort_values(by="f1_score", ascending=False)
df_resultados.to_csv(log_path, index=False)

pd.DataFrame(freq_optimos.most_common()).to_csv(freq_path, index=False,
                                                header=["feature", "frecuencia"])

print(f"\nğŸ“„ Resultados guardados en:")
print(f" - {log_path}")
print(f" - {freq_path}")

# Obtener las 10 columnas mÃ¡s frecuentes en Ã³ptimos locales
top10_features = [feature for feature, _ in freq_optimos.most_common(K)]

print(f"\nğŸ” Top {K} features mÃ¡s frecuentes en Ã³ptimos locales:")
print(top10_features)

# Entrenar un modelo con estas columnas
model_top10 = GaussianNB()
model_top10.fit(X_train[top10_features], y_train)
y_pred_top10 = model_top10.predict(X_test[top10_features])

# EvaluaciÃ³n
from sklearn.metrics import classification_report, f1_score, confusion_matrix

f1_top10 = f1_score(y_test, y_pred_top10)

print(f"\nğŸ“Š Resultados usando las {K} features mÃ¡s frecuentes:")
print(classification_report(y_test, y_pred_top10))
print(f"F1-score Top10 = {f1_top10:.4f}")

# Matriz de confusiÃ³n
cm_top10 = confusion_matrix(y_test, y_pred_top10)
print(f"Matriz de confusiÃ³n (Top-{K}):")
print(cm_top10)

# ComparaciÃ³n rÃ¡pida
print("\nğŸ“Œ ComparaciÃ³n Final")
print(f"Mejor F1-score Random Search: {mejor_f1:.4f}")
print(f"F1-score con Top10 frecuentes: {f1_top10:.4f}")

